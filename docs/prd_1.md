We’re building Mana’s Inspection module as an AI-first, guided inspection experience where the primary input is a user’s intent, expressed in natural language. Instead of forcing users to pick rigid templates or fill out long forms, the system begins by understanding what the user is trying to accomplish (for example, inspecting a vehicle before purchase, walking a property before move-in, or evaluating equipment on a job site) and the constraints they’re operating under (time available, environment, priorities). From that intent, the system initializes an inspection session that feels like an interactive guide rather than a checklist, while still producing structured, auditable inspection data.

The inspection itself is treated as a living process that evolves as the user discovers information. The system proposes an initial set of steps and then drives execution through an incremental, question-by-question loop. Each prompt is designed to be actionable in the moment and tuned to reduce cognitive load: the user is asked one thing at a time, encouraged to capture the right evidence, and continuously guided toward high-value checks. As the user answers, the system adapts—reordering steps, adding new ones, or branching into short “micro-flows” when the user reports something unexpected. This makes the experience equally suitable for planned workflows and ad-hoc discovery without requiring separate products.

A core requirement is that the system remains generic and interface-driven, rather than being hardcoded for a specific inspection type. The inspection engine operates on abstract concepts—targets, steps, observations, evidence, and collaboration—so it can support cars, buildings, equipment, or any other inspectable subject. On top of that generic foundation, the product will eventually allow the API to enforce what is supported in a given environment by applying filters and constraints: which evidence types are allowed, which step libraries or reasoning policies are enabled, what role actions are permitted, and what completion criteria apply. This creates a flexible platform that can be specialized per customer or per use case without changing the core interaction model.

Because the system is AI-first, it must also be coverage-aware and relevance-aware. The product should actively reduce the chance that users miss important details by tracking what has been checked against what is implied by the user’s intent, and then nudging the user back to critical items if they skip ahead or get distracted. At the same time, it should avoid derailing the flow by over-focusing on irrelevant observations; it can record low-priority notes but should gently steer the user back to the goal. The guiding principle is “keep the user moving forward” while still producing thorough, decision-ready results.

Collaboration is built into the inspection process from the start. An inspection can be shared mid-stream with other participants who can contribute comments, follow-up tasks, and additional evidence, without breaking the guided flow. Contributions from collaborators are incorporated into the inspection’s evolving plan so that important suggestions become actionable at the right time, not lost in a chat thread. The result is an inspection that feels like a shared working session, but remains structured and traceable.

Finally, the system must produce an inspection record that is both usable and trustworthy. AI-driven guidance is not allowed to become “magic” that silently mutates reality; the output must remain attributable, reviewable, and reversible as the product matures. The end state is a clean, decision-ready summary of what was found, what evidence supports it, what remains incomplete (if anything), and what follow-ups were created. This ensures that the AI makes inspections faster and more consistent, while keeping humans firmly in control of what is ultimately recorded.